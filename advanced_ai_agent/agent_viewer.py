import os
import glob
import yaml
import sys
import cv2
import json
import time
import ctypes
import threading
import numpy as np
from PIL import Image
import multiprocessing as mp
from datetime import datetime
from PIL import Image
from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QRect, pyqtSlot
from PyQt5.QtGui import QImage, QPixmap, QBrush, QDragEnterEvent, QDropEvent, QPen
from PyQt5.QtWidgets import (
  QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
  QLineEdit, QPushButton, QGraphicsView, QActionGroup,
  QApplication, QMainWindow, QGraphicsScene, QAction, QMenu, QFrame, 
)
from PyQt5.QtCore import Qt, QTimer, QThread

# from simple_llm import SimpleLLM
from advanced_ai_agent import AdvancedAgent
from utils.speech_bubble import SpeechBubble
# from voice.voice import VoiceSoundAivAPI
from resizeble_graphics_view import ResizableGraphicsView

from game.otthello_board_view import OthelloBoardView

os.chdir(os.path.dirname(os.path.abspath(__file__)))

# VIEWER_WIDTH = 480
# VIEWER_HIGHT = 527

USER_NAME = "ãƒã‚¹ã‚¿ãƒ¼"
MAX_STEPS = 10 # æœ€å¤§æ€è€ƒå›æ•°

VIEWER_SIZE = 300
INPUT_WIN_SIZE = 480 # å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
FONT_SIZE = 15
BASE_BUBBLE_DURATION = 3000 # ãµãã ã—ã®åŸºæœ¬ã®è¡¨ç¤ºç§’

# VIDEO_REVERSE = True # é€†å†ç”Ÿ
# FADE_MSEC = 0.5 # ãƒ•ã‚§ãƒ¼ãƒ‰ç§’æ•°
LINE_BREAK = True # èª­ç‚¹å¾Œã«æ”¹è¡Œ

# =========================
# å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã®ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼
# =========================
class InputGraphicsView(ResizableGraphicsView):
  imageDeleted = pyqtSignal() # ç”»åƒã®å‰Šé™¤
  dropImage = pyqtSignal(str) # ãƒ‰ãƒ©ãƒƒã‚°ãƒ‰ãƒ­ãƒƒãƒ—ã®ç”»åƒãƒ‘ã‚¹

  def __init__(self, parent=None):
    super().__init__(parent)
    
  # å³ã‚¯ãƒªãƒƒã‚¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¡¨ç¤º
  def show_context_menu(self, pos):
    menu = QMenu(self)

    # if self.input_mode:
    delete_action = QAction("ç”»åƒã‚’å‰Šé™¤", self)
    menu.addAction(delete_action)
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã‚¹ãƒ­ãƒƒãƒˆã®æ¥ç¶š
    delete_action.triggered.connect(self.delete_image)

    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
    if menu.actions():
      menu.exec_(self.mapToGlobal(pos))

  # --- ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œ ---
  def dragEnterEvent(self, event: QDragEnterEvent):    
    if event.mimeData().hasUrls():
      event.acceptProposedAction()
    else:
      event.ignore()

  def dragMoveEvent(self, event):    
    if event.mimeData().hasUrls():
      event.acceptProposedAction()
    else:
      event.ignore()

  def dropEvent(self, event: QDropEvent):
    urls = event.mimeData().urls()
    if urls:
      path = urls[0].toLocalFile()
      if path:
        self.dropImage.emit(path)
        
    event.ignore()

  # ç”»åƒã‚’å‰Šé™¤ã™ã‚‹ã‚¹ãƒ­ãƒƒãƒˆ
  def delete_image(self):
    # ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚¯ãƒªã‚¢
    self.display_clear()
   
    # ç”»åƒãŒå‰Šé™¤ã•ã‚ŒãŸã“ã¨ã‚’MainWindowã«é€šçŸ¥
    self.imageDeleted.emit()
       
# =========================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã®ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼
# =========================
class AgentGraphicsView(ResizableGraphicsView):
  speechMode = pyqtSignal(bool) # éŸ³å£°å…¥åŠ›
  inputWindow = pyqtSignal() # ç”»åƒå…¥åŠ›ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
  selectAgent = pyqtSignal(int) # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠ
  gameWindow = pyqtSignal(int) # ã‚ªã‚»ãƒ­ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

  def __init__(self, parent=None, vision_flg=False):
    super().__init__(parent)

    # ã€Œç”»åƒå…¥åŠ›ç”»é¢ã€ç”¨ã®ãƒ¢ãƒ¼ãƒ‰
    # self.input_mode = input_mode
    self.owner = parent

    # å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¡¨ç¤º
    self.vision_flg = vision_flg

    # éŸ³å£°å…¥åŠ›
    self.speech_use = False
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ‡ã‚Šæ›¿ãˆç”¨ã®åå‰ãƒªã‚¹ãƒˆ
    self.agent_names = []
    self.select_agent_idx = 0
    
    # ã‚²ãƒ¼ãƒ å
    self.game_names = []

    self.setAcceptDrops(True)


  # å³ã‚¯ãƒªãƒƒã‚¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¡¨ç¤º
  def show_context_menu(self, pos):
    menu = QMenu(self)

    # éŸ³å£°å…¥åŠ›
    speech_action = QAction("éŸ³å£°å…¥åŠ›", self)
    speech_action.setCheckable(True)
    speech_action.setChecked(self.speech_use)  # ç¾åœ¨ã®çŠ¶æ…‹ã‚’åæ˜ 
    
    # def update_speech_use(checked):
    #   self.speech_use = checked
    # # ãƒã‚§ãƒƒã‚¯çŠ¶æ…‹ãŒå¤‰ã‚ã£ãŸã‚‰å¤‰æ•°ã‚’æ›´æ–°
    # speech_action.toggled.connect(update_speech_use)
    menu.addAction(speech_action)
    
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã‚¹ãƒ­ãƒƒãƒˆã®æ¥ç¶š
    speech_action.toggled.connect(self.speech_enable)
    # speech_action.triggered.connect(self.speechMode.emit)    

    menu.addSeparator()
      
    if self.vision_flg:
      input_win_action = QAction("ç”»åƒå…¥åŠ›ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", self)
      menu.addAction(input_win_action)
      
      # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã‚¹ãƒ­ãƒƒãƒˆã®æ¥ç¶š
      input_win_action.triggered.connect(self.inputWindow.emit)    
      if self.agent_names:
        menu.addSeparator()
    
    if self.agent_names:
      # ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã‚µãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ä½œæˆ
      agent_menu = menu.addMenu("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
      if self.owner.agent_running:
        agent_menu.setEnabled(False) # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ‡ã‚Šæ›¿ãˆOFF

      # ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆï¼ˆæ’ä»–é¸æŠç”¨ï¼‰
      action_group = QActionGroup(menu)
      action_group.setExclusive(True)

      for i, name in enumerate(self.agent_names):
        agent_action = QAction(name, agent_menu)
        agent_action.setCheckable(True)
        
        # ã‚¯ãƒªãƒƒã‚¯æ™‚ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å›ºå®šã—ã¦æ¸¡ã™
        agent_action.triggered.connect(lambda checked=False, idx=i: self.select_agent(idx))
        
        action_group.addAction(agent_action)   # ã‚°ãƒ«ãƒ¼ãƒ—ã«ç™»éŒ²
        agent_menu.addAction(agent_action)

      # ç¾åœ¨é¸æŠä¸­ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒã‚§ãƒƒã‚¯ã‚’ã¤ã‘ã‚‹
      if 0 <= self.select_agent_idx < len(action_group.actions()):
        action_group.actions()[self.select_agent_idx].setChecked(True)
  
      # ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã‚µãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ä½œæˆ
      if self.game_names:
        game_menu = menu.addMenu("ã‚²ãƒ¼ãƒ ")
        for i, name in enumerate(self.game_names):
          game_action = QAction(name, game_menu)
          # agent_action.setCheckable(True)
          
          # ã‚¯ãƒªãƒƒã‚¯æ™‚ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å›ºå®šã—ã¦æ¸¡ã™
          game_action.triggered.connect(lambda checked=False, idx=i: self.select_game(idx))
          
          # action_group.addAction(agent_action)   # ã‚°ãƒ«ãƒ¼ãƒ—ã«ç™»éŒ²
          game_menu.addAction(game_action)
        
      # othello_action = QAction("ã‚ªã‚»ãƒ­", game_menu)
      # othello_action.triggered.connect(self.gameWindow.emit)
      
    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
    if menu.actions():
      menu.exec_(self.mapToGlobal(pos))
  
  # éŸ³å£°å…¥åŠ›ãƒã‚§ãƒƒã‚¯
  def speech_enable(self, chk):
    self.speech_use = chk
    self.speechMode.emit(chk)
  
  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤‰æ›´
  def select_agent(self, idx):
    self.select_agent_idx = idx
    self.selectAgent.emit(idx)
  
  # ã‚²ãƒ¼ãƒ ã®é¸æŠ
  def select_game(self, idx):
    # self.select_agent_idx = idx
    self.gameWindow.emit(idx)

# =========================
# Agentå‡¦ç†ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰
# =========================
class AgentWorker(QThread):
  finished = pyqtSignal(object, object)  # å¿œç­”ã‚’è¿”ã™ã‚·ã‚°ãƒŠãƒ«

  def __init__(self, agent, user_input, image_path=None, queue_thought=None, speech_flg=False): #image:Image=None):
    super().__init__()
    self.agent = agent
    self.user_input = user_input
    # self.image = image
    self.image_path = image_path
    self.queue_thought = queue_thought
    self.speech_flg= speech_flg # éŸ³å£°å…¥åŠ›

  def run(self):
    # LLMãªã©é‡ã„å‡¦ç†ã¯ã“ã“ã§å®Ÿè¡Œ
    # response = self.agent.run(self.user_input,  max_steps=MAX_STEPS, user_name=USER_NAME, image=self.image)
    start_time = time.time()
    response, action = self.agent.run(self.user_input,  max_steps=MAX_STEPS, user_name=USER_NAME, image_path=self.image_path, queue_thought=self.queue_thought, speech_flg=self.speech_flg)
    print(f"æœ€çµ‚å¿œç­”æ™‚é–“: {time.time()-start_time:.3f}s")
    self.finished.emit(response, action)  # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã¸æˆ»ã™

# =========================
# å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
# =========================
class InputImageWindow(QMainWindow):
  def __init__(self, parent=None):
    super().__init__(parent)

    self.image_path:str = None
    self.image:Image = None

    # === UIè¨­å®š ===
    self.setWindowTitle(f"å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦")
        
    # ç”»é¢ã‚µã‚¤ã‚º(ä½œæ¥­é ˜åŸŸ)
    screen = QApplication.primaryScreen()
    rect = screen.availableGeometry()
    width = rect.width()
    height = rect.height()
    # print(f"ãƒ¢ãƒ‹ã‚¿ã‚µã‚¤ã‚º(ä½œæ¥­é ˜åŸŸ): {width} x {height}")
          
    viewer_w = viewer_h = INPUT_WIN_SIZE
    
    self.setGeometry(int((width-viewer_w)/2), int((height-viewer_h)/2), viewer_w, viewer_h)

    central = QWidget(self)
    self.setCentralWidget(central)
    layout = QVBoxLayout(central)
    layout.setContentsMargins(0, 0, 0, 0)
    layout.setSpacing(0)
    
    # self.viewer = ResizableGraphicsView(input_mode=True)
    self.viewer = InputGraphicsView(self)
    layout.addWidget(self.viewer)
        
    # layout = QVBoxLayout()
    # layout.addWidget(QLabel("ã“ã“ã«ResizableGraphicsViewã‚’é…ç½®"))
    # self.setLayout(layout)
    
    # === ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š ===
    self.viewer.dropImage.connect(self.input_image)
    self.viewer.imageDeleted.connect(self.delete_image)

  # ãƒ•ã‚©ãƒ¼ãƒ ã‚’é–‰ã˜ãŸã¨ãã®ã‚¤ãƒ™ãƒ³ãƒˆ
  def closeEvent(self, event):
    # ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚¯ãƒªã‚¢
    self.viewer.display_clear()

    # ç”»åƒæƒ…å ±å‰Šé™¤
    self.delete_image()
    
    super().closeEvent(event)
     
  # å…¥åŠ›ç”»åƒã‚’è¨­å®š
  def input_image(self, img_path, bg_color=(255, 255, 255)):
    self.image = None
    self.image_path = None
    try:
      if img_path and os.path.isfile(img_path):
        self.image_path = img_path
        img = Image.open(img_path)
        if img.mode in ("RGBA", "LA") or ("transparency" in img.info):
          # Î±ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ç™½èƒŒæ™¯ã«åˆæˆ
          img = img.convert("RGBA")  # ã¾ãš RGBA ã«çµ±ä¸€
          bg_img = Image.new("RGB", img.size, bg_color)
          bg_img.paste(img, mask=img.split()[3])  # Î±ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ãƒã‚¹ã‚¯ã¨ã—ã¦ä½¿ç”¨
        else:
          bg_img = img.convert("RGB")

        self.image = bg_img
        self.image_path = img_path
        
        # self.image = Image.open(img_path).convert("RGB")
        self.viewer.display_image(self.image)
    except Exception as e:
      print(f"Error: {e}")
    
  # ç”»åƒæƒ…å ±å‰Šé™¤
  def delete_image(self):
    self.image_path = None
    self.image = None
    
    
# =========================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¹
# =========================
class AgentViewer(QMainWindow):
  def __init__(self, agent):
    super().__init__()

    self.agent = agent
    self.video_paths = agent.video_paths
    self.video_reverse = agent.video_reverse
    self.video_fade_msec = agent.video_fade_msec

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­
    self.agent_running = False
    
    # å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
    self.input_window = None
    
    # ã‚²ãƒ¼ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
    self.othello_window = None # ã‚ªã‚»ãƒ­
    
    # éŸ³å£°å…¥åŠ›ãƒ•ãƒ©ã‚°
    self.speech_use = False
    
    # === UIè¨­å®š ===
    title_add = f"ï¼š{agent.name}" if agent.name else "0"
    self.setWindowTitle(f"AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ{title_add}")
        
    # ç”»é¢ã‚µã‚¤ã‚º
    user32 = ctypes.windll.user32
    user32.SetProcessDPIAware()  # é«˜DPIå¯¾å¿œ
    self.screen_width = user32.GetSystemMetrics(0)
    self.screen_height = user32.GetSystemMetrics(1)
    # print(f"ãƒ¢ãƒ‹ã‚¿ã‚µã‚¤ã‚º: {self.screen_width} x {self.screen_height}")

    screen = QApplication.primaryScreen()
    rect = screen.availableGeometry()
    width = rect.width()
    height = rect.height()
    # print(f"ãƒ¢ãƒ‹ã‚¿ã‚µã‚¤ã‚º(ä½œæ¥­é ˜åŸŸ): {width} x {height}")
    
    viewer_w = VIEWER_SIZE
    viewer_h = viewer_w + 40
    
    self.setGeometry(int((width-viewer_w)/2), int((height-viewer_h)/2), viewer_w, viewer_h)

    self.bubble_queue = mp.Queue() # ãƒãƒ–ãƒ«ã«è¡¨ç¤ºã™ã‚‹ã‚­ãƒ¥ãƒ¼
    self.bubble_queue_thought = mp.Queue()
    self.bubble = None
    
    vision_flg = self.agent.vision_model if self.agent else False
    
    central = QWidget(self)
    self.setCentralWidget(central)
    layout = QVBoxLayout(central)
    layout.setContentsMargins(0, 0, 0, 0)
    layout.setSpacing(0)

    # === ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ˜ åƒ ===
    # self.viewer = ResizableGraphicsView(input_mode=False, vision_flg=vision_flg)
    self.viewer = AgentGraphicsView(self, vision_flg=vision_flg)

    layout.addWidget(self.viewer)

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ‡ã‚Šæ›¿ãˆ
    self.viewer.agent_names = [cfg["name"] for cfg in agent.agents_cfg]
    self.viewer.select_agent_idx = agent.select_idx
  
    # ã‚²ãƒ¼ãƒ ã®ãƒ„ãƒ¼ãƒ«ãŒã‚ã‚‹ã¨ãã ã‘ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«è¡¨ç¤º
    self.viewer.game_names = []
    for tool in self.agent.tools.values():
      if tool.type() == "game":
        self.viewer.game_names.append(tool.title())
      
    # === å…¥åŠ›UI ===
    input_layout = QHBoxLayout()
    self.input_box = QLineEdit()
    self.input_box.setPlaceholderText("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...")
    self.send_button = QPushButton("é€ä¿¡")
    input_layout.addWidget(self.input_box)
    input_layout.addWidget(self.send_button)
    layout.addLayout(input_layout)

    self.input_box.setStyleSheet(f"font-size: {FONT_SIZE}px;")

    # === åˆæœŸãƒ•ã‚©ãƒ¼ã‚«ã‚¹è¨­å®š ===
    self.input_box.setFocus()
    
    # === ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š ===
    self.send_button.clicked.connect(self.on_send_message)
    self.input_box.returnPressed.connect(self.on_send_message)

    # === å‹•ç”»å†ç”Ÿæº–å‚™ ===
    self.create_video_frame()
    
    # === ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š ===
    self.viewer.speechMode.connect(self.speech_input) # éŸ³å£°å…¥åŠ›
    self.viewer.inputWindow.connect(self.view_input)
    self.viewer.selectAgent.connect(self.change_agent)
    self.viewer.gameWindow.connect(self.view_game)

    # === ã‚¿ã‚¤ãƒãƒ¼ã§ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–° ===
    self.timer = QTimer(self)
    self.timer.timeout.connect(self._update_frame)
    self.timer.start(33)  # ç´„30fps
    self.timer.start(int(1/self.fps*1000)) # ç´„30fps

    # QTimerã§ãƒ«ãƒ¼ãƒ—å‡¦ç†
    q_timer = QTimer(self)
    q_timer.timeout.connect(self._check_bubble_queue)
    q_timer.start(100) # 100msãƒã‚§ãƒƒã‚¯
 
  # å‹•ç”»ç”¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
  def create_video_frame(self):
    self.current_frame = 0
    self.frames, self.fps = self.load_video_sequence(self.video_paths, fade_duration=self.video_fade_msec, reverse_flg=self.video_reverse)

  # å‹•ç”»ã‚’ãƒ­ãƒ¼ãƒ‰
  def load_video_sequence(self, video_paths, fade_duration=0.5, reverse_flg=False):
    def read_frames(cap):
      frames = []
      while True:
        ret, frame = cap.read()
        if not ret:
          break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
      return frames

    def create_fade_transition(last_frames, next_frames, fade_frames):
      transition = []
      last_len = len(last_frames)
      next_len = len(next_frames)
      for i in range(fade_frames):
        alpha = (i + 1) / (fade_frames + 1)
        last_idx = max(0, last_len - fade_frames + i)
        next_idx = min(next_len - 1, i)
        blended = cv2.addWeighted(
          last_frames[last_idx], 1 - alpha,
          next_frames[next_idx], alpha,
          0
        )
        transition.append(blended)
      return transition

    # ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“ã«å¯¾å¿œã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æ±‚ã‚ã‚‹
    temp_cap = cv2.VideoCapture(video_paths[0])
    fps = temp_cap.get(cv2.CAP_PROP_FPS) or 30
    temp_cap.release()
    fade_frames = int(fps * fade_duration)

    sequence_frames = []
    all_frames_per_video = []

    # å„å‹•ç”»ã‚’èª­ã¿è¾¼ã¿ï¼ˆé †å†ç”Ÿï¼‹é€†å†ç”Ÿã«ã‚‚å¯¾å¿œï¼‰
    for path in video_paths:
      if not os.path.isfile(path):
        all_frames_per_video.append([])
        continue

      cap = cv2.VideoCapture(path)
      frames = read_frames(cap)
      cap.release()

      if reverse_flg:
        frames_combined = frames + frames[::-1]
      else:
        frames_combined = frames

      all_frames_per_video.append(frames_combined)

    n = len(all_frames_per_video)
    if n == 0:
      return [], fps

    # ãƒ•ã‚§ãƒ¼ãƒ‰ä»˜ãã§å…¨å‹•ç”»ã‚’çµåˆ
    for i in range(n):
      frames = all_frames_per_video[i]
      if not frames:
        continue

      sequence_frames.extend(frames)

      # æ¬¡ã®å‹•ç”»ï¼ˆæœ€å¾Œâ†’æœ€åˆã‚‚å«ã‚ã‚‹ï¼‰
      next_i = (i + 1) % n
      next_frames = all_frames_per_video[next_i]
      if not next_frames:
        continue

      # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
      fade_transition = create_fade_transition(
        frames[-fade_frames:] if len(frames) >= fade_frames else frames,
        next_frames[:fade_frames] if len(next_frames) >= fade_frames else next_frames,
        min(fade_frames, len(frames), len(next_frames))
      )

      # é€šå¸¸ï¼šã™ã¹ã¦ã®æ¥ç¶šã«ãƒ•ã‚§ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹ï¼ˆæœ€å¾Œâ†’æœ€åˆã‚‚å«ã‚€ï¼‰
      sequence_frames.extend(fade_transition)

    return sequence_frames, fps

  # --------------------------
  # ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–°
  # --------------------------
  def _update_frame(self):
    if not self.frames:
      return
    frame = self.frames[self.current_frame]
    self.current_frame = (self.current_frame + 1) % len(self.frames)
    pil_img = Image.fromarray(frame)
    self.viewer.display_image(pil_img)

  # --------------------------
  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ
  # --------------------------
  def on_send_message(self, message=None, speech_use=False):
    if not message:
      user_input = self.input_box.text().strip()
      if not user_input:
        return
      if self.agent_running:
        return
    else:
      user_input = message

    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’éæ´»æ€§
    self.send_button.setEnabled(False)
    self.input_box.setEnabled(False)
    
    self.agent_running = True

    # === ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‹•ä½œ ===
    # image = self.input_window.image if self.input_window else None
    image_path = self.input_window.image_path if self.input_window else None
    
    # self.worker_thread = AgentWorker(self.agent, user_input, image)
    self.worker_thread = AgentWorker(self.agent, user_input, image_path, self.bubble_queue_thought, speech_use)
    self.worker_thread.finished.connect(self.on_agent_finished)
    self.worker_thread.start()
    
  # --------------------------
  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”å®Œäº†æ™‚
  # --------------------------
  def on_agent_finished(self, response, action):
    print(f"ğŸ’¬ å¿œç­”: {response}")

    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ç©ºã«
    self.input_box.clear()

    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’æ´»æ€§
    self.send_button.setEnabled(True)
    self.input_box.setEnabled(True)
    # self.viewer.agent_menu.setEnabled(True) # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ‡ã‚Šæ›¿ãˆON
    self.input_box.setFocus()

    if response is not None:

      if LINE_BREAK:
        response = response.replace("\n\n", "\n").replace("ã€‚\n", "ã€‚").replace("ã€‚", "ã€‚\n").strip()

      # ãµãã ã—è¡¨ç¤º
      self.bubble_queue.put(response)

      if self.agent.voice:
        self.agent.voice.create_voice(response)

    
    if action:
      if action == "<open:othello>":
        idx = self.viewer.game_names.index("ã‚ªã‚»ãƒ­")
        self.view_game(idx)
      elif action == "<close:othello>":
        if self.othello_window:
          self.othello_window.close()
      else: # action == "<othello>":
        if self.othello_window:
          # ã‚ªã‚»ãƒ­ã‚²ãƒ¼ãƒ ç”»é¢ãŒé–‹ã„ã¦ã„ã‚‹ã¨ãã¯ç”»é¢æ›´æ–°
          self.othello_window.draw_board()    

    self.agent_running = False
    
    # bubble = False
    # if win_image_process and hasattr(win_image_process, "x"):
    #   x = win_image_process.x
    #   y = win_image_process.y
    #   width = win_image_process.width
    #   bubble = win_image_process.bubble

    #   if bubble:
    #     self.bubble_queue.put({"text":chara_msg, "x":x+width-40, "y":y-40, "width":width})

  # ãµãã ã—ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
  def _check_bubble_queue(self):
    if not self.bubble_queue.empty():
      rect = self.geometry()
      # print(f"ä½ç½®ã¨ã‚µã‚¤ã‚º: x={rect.x()}, y={rect.y()}, w={rect.width()}, h={rect.height()}")        
      text = self.bubble_queue.get()
      if text == "": text = "ï½¥ï½¥ï½¥"
        
      x = rect.x() + rect.width() #dic["x"]
      y = rect.y() # dic["y"]
      max_width = min(int(rect.width() * 1.0), self.screen_width)
      # è¡¨ç¤ºç§’(æ–‡å­—æ•°ã«å¿œã˜ã¦å¤‰ãˆã‚‹)
      duration = min(BASE_BUBBLE_DURATION + len(text) * 130, 60000)

      # print(f"ãµãã ã—è¡¨ç¤ºç§’: {duration/1000:.3f}s")
      
      # del self.bubble
      # self.bubble = None
      
      SpeechBubble(text, x, y, max_width=max_width, duration=duration)

    # æ€è€ƒã®å¹ãå‡ºã—è¡¨ç¤º
    if not self.bubble_queue_thought.empty():
      rect = self.geometry()
      text = self.bubble_queue_thought.get()
      if not text: text = "ï½¥ï½¥ï½¥"
      
      margin = 7
      #  + rect.width() #dic["x"]
      y = rect.y() + rect.height() + 2
      max_width = min(int(rect.width() * 1.0), self.screen_width) - margin * 4
      x = rect.x()
      
      # è¡¨ç¤ºç§’(æ–‡å­—æ•°ã«å¿œã˜ã¦å¤‰ãˆã‚‹)
      duration = min(BASE_BUBBLE_DURATION + len(text) * 130, 60000)

      # print(f"ãµãã ã—(æ€è€ƒ)è¡¨ç¤ºç§’: {duration/1000:.3f}s")
      # del self.bubble
      # self.bubble = None
      
      SpeechBubble(text, x, y, max_width=max_width, duration=duration, tail_direction=1, tail_shape=1)
  
  # éŸ³å£°å…¥åŠ›ã‚’ä½¿ç”¨
  def speech_input(self, speech_flg):

    self.speech_use = speech_flg

    if speech_flg:
      from speech_recognizer import LlmSignals, SpeechRecognizer
      
      self.audio_enabled = True

      self.signals = LlmSignals()

      # ã‚·ã‚°ãƒŠãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
      self.signals.recognized.connect(self.on_recognized_gui_thread)

      self.recognizer = SpeechRecognizer(self.signals) 
      threading.Thread(target=self.recognizer.start, daemon=True).start()
      print("ğŸ™ï¸ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
    else:
      self.audio_enabled = False
      if self.recognizer:
        self.recognizer.stop()
        self.recognizer = None
      print("ğŸ›‘ éŸ³å£°å…¥åŠ›ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

  @pyqtSlot(str) 
  def on_recognized_gui_thread(self, text):
    """éŸ³å£°èªè­˜çµæœã‚’GUIã‚¹ãƒ¬ãƒƒãƒ‰ã§å‡¦ç†"""
    # self.textbox.append(f"ğŸ‘¤ ã‚ãªãŸ: {text}")
    print(f"éŸ³å£°æ¤œçŸ¥: {text}")
    if self.agent_running:
      print(f" => ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€è€ƒä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
      return
    self.input_box.setText(text)
    self.on_send_message(speech_use=True)
    
  # å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¡¨ç¤º
  def view_input(self):
    if self.input_window is None:
      self.input_window = InputImageWindow()
      self.input_window.setParent(self, Qt.Window)
    self.input_window.show()
    self.input_window.raise_()
    self.input_window.activateWindow()

  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ‡ã‚Šæ›¿ãˆ
  def change_agent(self, idx):
    if idx != self.agent.select_idx:
      self.agent.change(idx)
      self.video_paths = self.agent.video_paths
      self.video_reverse = self.agent.video_reverse
      self.video_fade_msec = self.agent.video_fade_msec
      
      title_add = f"ï¼š{agent.name}" if agent.name else "0"
      self.setWindowTitle(f"AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ{title_add}")
      
      # å…¥åŠ›ç”»åƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¡¨ç¤º
      self.viewer.vision_flg = self.agent.vision_model
    
      self.viewer.game_names = []
      for tool in self.agent.tools.values():
        if tool.type() == "game":
          self.viewer.game_names.append(tool.title())
      
      if not "othello" in self.viewer.game_names:
        # ã‚²ãƒ¼ãƒ ã®ãƒ„ãƒ¼ãƒ«ãŒãªã„å ´åˆã¯é–‰ã˜ã‚‹
        self.agent.mode = "nomal"
        
        if self.othello_window is not None:
          self.othello_window.close()
          self.othello_window = None # ã‚ªã‚»ãƒ­

      # å‹•ç”»ã®å¤‰æ›´
      self.create_video_frame()

  # ã‚²ãƒ¼ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¡¨ç¤º
  def view_game(self, idx):
    game_title = self.viewer.game_names[idx]
    for tool in self.agent.tools.values():
      if tool.title() == game_title:
        if self.othello_window is None:
          self.othello_window = OthelloBoardView(tool, self, ops_turn=0)
          self.othello_window.setParent(self, Qt.Window)
        self.agent.mode = tool.name()
        self.othello_window.draw_board()
        self.othello_window.show()
        self.othello_window.raise_()
        self.othello_window.activateWindow()


# yamlã®èª­ã¿è¾¼ã¿
def load_all_yaml_files(yaml_dir_path):
  yaml_files = glob.glob(os.path.join(yaml_dir_path, '**', '*.y*ml'), recursive=True)
  all_data = []

  for file_path in yaml_files:
    with open(file_path, 'r', encoding='utf-8') as f:
      try:
        data = yaml.safe_load(f)
        all_data.append(data)
      except yaml.YAMLError as e:
        print(f"âš ï¸ YAMLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

  return all_data

# =========================
# å®Ÿè¡Œéƒ¨åˆ†
# =========================
if __name__ == "__main__":

  ollama_host = 'http://192.168.1.100:11434'

  # è¨­å®šã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ(yaml)ã‚’èª­ã¿è¾¼ã¿
  agent_cfgs = load_all_yaml_files("./agent_cfg")
  agent = AdvancedAgent(agent_cfgs, def_idx=0, host=ollama_host)

  # ãƒ•ã‚©ãƒ¼ãƒ ã‚’èµ·å‹•
  app = QApplication(sys.argv)  
  viewer = AgentViewer(agent)
  viewer.show()

  sys.exit(app.exec_())
  
# ã€å…¥åŠ›ä¾‹ã€‘
# ã“ã‚“ã«ã¡ã¯ã€‚
# æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
# 12345678901234567890 * 98765432109876543210 ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚
# å††å‘¨ç‡ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
# ã‚‚ã£ã¨ä¸‹ã®æ¡ã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
